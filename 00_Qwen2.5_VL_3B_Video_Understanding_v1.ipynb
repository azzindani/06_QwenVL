{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windows omni_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T07:06:22.308399Z",
     "iopub.status.busy": "2025-04-14T07:06:22.308179Z",
     "iopub.status.idle": "2025-04-14T07:06:49.493562Z",
     "shell.execute_reply": "2025-04-14T07:06:49.492696Z",
     "shell.execute_reply.started": "2025-04-14T07:06:22.308379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import math\n",
    "import hashlib\n",
    "import requests\n",
    "import numpy as np\n",
    "import decord\n",
    "import markdown\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from transformers import (\n",
    "    Qwen2_5_VLForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    AutoProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    TextStreamer\n",
    ")\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "from IPython.display import display, Markdown\n",
    "from decord import VideoReader, cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T07:06:49.494981Z",
     "iopub.status.busy": "2025-04-14T07:06:49.494404Z",
     "iopub.status.idle": "2025-04-14T07:09:20.429998Z",
     "shell.execute_reply": "2025-04-14T07:09:20.429296Z",
     "shell.execute_reply.started": "2025-04-14T07:06:49.494957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = './00_Model/Qwen2.5-VL-3B-Instruct'\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    ").to(device) #''\n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frames(video_path, num_frames = 128, cache_dir = '.cache'):\n",
    "    os.makedirs(cache_dir, exist_ok = True)\n",
    "\n",
    "    video_hash = hashlib.md5(video_path.encode('utf-8')).hexdigest()\n",
    "    if video_path.startswith('http://') or video_path.startswith('https://'):\n",
    "        video_file_path = os.path.join(cache_dir, f'{video_hash}.mp4')\n",
    "        if not os.path.exists(video_file_path):\n",
    "            download_video(video_path, video_file_path)\n",
    "    else:\n",
    "        video_file_path = video_path\n",
    "\n",
    "    frames_cache_file = os.path.join(cache_dir, f'{video_hash}_{num_frames}_frames.npy')\n",
    "    timestamps_cache_file = os.path.join(cache_dir, f'{video_hash}_{num_frames}_timestamps.npy')\n",
    "\n",
    "    if os.path.exists(frames_cache_file) and os.path.exists(timestamps_cache_file):\n",
    "        frames = np.load(frames_cache_file)\n",
    "        timestamps = np.load(timestamps_cache_file)\n",
    "        return video_file_path, frames, timestamps\n",
    "\n",
    "    vr = VideoReader(video_file_path, ctx = cpu(0))\n",
    "    total_frames = len(vr)\n",
    "\n",
    "    indices = np.linspace(0, total_frames - 1, num = num_frames, dtype = int)\n",
    "    frames = vr.get_batch(indices).asnumpy()\n",
    "    timestamps = np.array([vr.get_frame_timestamp(idx) for idx in indices])\n",
    "\n",
    "    np.save(frames_cache_file, frames)\n",
    "    np.save(timestamps_cache_file, timestamps)\n",
    "    \n",
    "    return video_file_path, frames, timestamps\n",
    "\n",
    "def create_image_grid(images, num_columns = 8):\n",
    "    pil_images = [Image.fromarray(image) for image in images]\n",
    "    num_rows = math.ceil(len(images) / num_columns)\n",
    "\n",
    "    img_width, img_height = pil_images[0].size\n",
    "    grid_width = num_columns * img_width\n",
    "    grid_height = num_rows * img_height\n",
    "    grid_image = Image.new('RGB', (grid_width, grid_height))\n",
    "\n",
    "    for idx, image in enumerate(pil_images):\n",
    "        row_idx = idx // num_columns\n",
    "        col_idx = idx % num_columns\n",
    "        position = (col_idx * img_width, row_idx * img_height)\n",
    "        grid_image.paste(image, position)\n",
    "\n",
    "    return grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    prompt,\n",
    "    video_path,\n",
    "    system_prompt = 'You are a helpful assistant',\n",
    "    max_new_tokens = 2048,\n",
    "    total_pixels = 20480 * 28 * 28,\n",
    "    min_pixels = 16 * 28 * 28\n",
    "):\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : [\n",
    "                {\n",
    "                    'type' : 'video',\n",
    "                    'video' : video_path,\n",
    "                    'total_pixels' : total_pixels,\n",
    "                    'min_pixels' : min_pixels,\n",
    "                },\n",
    "                {'type' : 'text', 'text' : prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize = False, add_generation_prompt = True\n",
    "    )\n",
    "    print('input:\\n', text)\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info([messages], return_video_kwargs = True)\n",
    "    fps_inputs = video_kwargs['fps']\n",
    "    print('video input:', video_inputs[0].shape)\n",
    "    num_frames, _, resized_height, resized_width = video_inputs[0].shape\n",
    "    print('num of video tokens:', int(num_frames / 2 * resized_height / 28 * resized_width / 28))\n",
    "    inputs = processor(\n",
    "        text = [text],\n",
    "        images = image_inputs,\n",
    "        videos = video_inputs,\n",
    "        fps = fps_inputs,\n",
    "        padding = True,\n",
    "        return_tensors = 'pt',\n",
    "    )\n",
    "    inputs = inputs.to('cuda')\n",
    "\n",
    "    streamer = TextStreamer(processor.tokenizer, skip_special_tokens = True, skip_prompt = True)\n",
    "\n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens = max_new_tokens, streamer = streamer)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens = True, clean_up_tokenization_spaces = False\n",
    "    )\n",
    "    return output_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.01 Detect Certain Object in the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "video_path = './00_Dataset/50221078283.mp4'\n",
    "prompt = '请用表格总结一下视频中的商品特点'\n",
    "\n",
    "video_path, frames, timestamps = get_video_frames(video_path, num_frames = 32)\n",
    "response = inference(prompt, video_path)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "omni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

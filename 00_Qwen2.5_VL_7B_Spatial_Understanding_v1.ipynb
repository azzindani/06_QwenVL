{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windows omni_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 Install & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T07:06:22.308399Z",
     "iopub.status.busy": "2025-04-14T07:06:22.308179Z",
     "iopub.status.idle": "2025-04-14T07:06:49.493562Z",
     "shell.execute_reply": "2025-04-14T07:06:49.492696Z",
     "shell.execute_reply.started": "2025-04-14T07:06:22.308379Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import random\n",
    "import io\n",
    "import ast\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from transformers import (\n",
    "    Qwen2_5_VLForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    AutoProcessor,\n",
    "    BitsAndBytesConfig,\n",
    "    TextStreamer\n",
    ")\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_use_double_quant = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T07:06:49.494981Z",
     "iopub.status.busy": "2025-04-14T07:06:49.494404Z",
     "iopub.status.idle": "2025-04-14T07:09:20.429998Z",
     "shell.execute_reply": "2025-04-14T07:09:20.429296Z",
     "shell.execute_reply.started": "2025-04-14T07:06:49.494957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_path = './00_Model/Qwen2.5-VL-7B-Instruct-unsloth-bnb-4bit'\n",
    "\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config = bnb_config,\n",
    "    device_map = 'auto',\n",
    ").to(device) #''\n",
    "processor = AutoProcessor.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Define Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def decode_xml_points(text):\n",
    "    try:\n",
    "        root = ET.fromstring(text)\n",
    "        num_points = (len(root.attrib) - 1) // 2\n",
    "        points = []\n",
    "        for i in range(num_points):\n",
    "            x = root.attrib.get(f'x{i+1}')\n",
    "            y = root.attrib.get(f'y{i+1}')\n",
    "            points.append([x, y])\n",
    "        alt = root.attrib.get('alt')\n",
    "        phrase = root.text.strip() if root.text else None\n",
    "        return {\n",
    "            \"points\": points,\n",
    "            \"alt\": alt,\n",
    "            \"phrase\": phrase\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "def plot_bounding_boxes(im, bounding_boxes, input_width, input_height):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on an image with markers for each a name, using PIL, normalized coordinates, and different colors.\n",
    "\n",
    "    Args:\n",
    "        img_path: The path to the image file.\n",
    "        bounding_boxes: A list of bounding boxes containing the name of the object\n",
    "         and their positions in normalized [y1 x1 y2 x2] format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    print(img.size)\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Define a list of colors\n",
    "    colors = [\n",
    "    'red',\n",
    "    'green',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'orange',\n",
    "    'pink',\n",
    "    'purple',\n",
    "    'brown',\n",
    "    'gray',\n",
    "    'beige',\n",
    "    'turquoise',\n",
    "    'cyan',\n",
    "    'magenta',\n",
    "    'lime',\n",
    "    'navy',\n",
    "    'maroon',\n",
    "    'teal',\n",
    "    'olive',\n",
    "    'coral',\n",
    "    'lavender',\n",
    "    'violet',\n",
    "    'gold',\n",
    "    'silver',\n",
    "    ] + additional_colors\n",
    "\n",
    "    # Parsing out the markdown fencing\n",
    "    bounding_boxes = parse_json(bounding_boxes)\n",
    "\n",
    "    font = ImageFont.truetype('./00_Dataset/NotoSansCJK-Regular.ttc', size = 14)\n",
    "\n",
    "    try:\n",
    "        json_output = ast.literal_eval(bounding_boxes)\n",
    "    except Exception as e:\n",
    "        end_idx = bounding_boxes.rfind('\"}') + len('\"}')\n",
    "        truncated_text = bounding_boxes[:end_idx] + \"]\"\n",
    "        json_output = ast.literal_eval(truncated_text)\n",
    "\n",
    "    # Iterate over the bounding boxes\n",
    "    for i, bounding_box in enumerate(json_output):\n",
    "        # Select a color from the list\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # Convert normalized coordinates to absolute coordinates\n",
    "        abs_y1 = int(bounding_box[\"bbox_2d\"][1]/input_height * height)\n",
    "        abs_x1 = int(bounding_box[\"bbox_2d\"][0]/input_width * width)\n",
    "        abs_y2 = int(bounding_box[\"bbox_2d\"][3]/input_height * height)\n",
    "        abs_x2 = int(bounding_box[\"bbox_2d\"][2]/input_width * width)\n",
    "\n",
    "        if abs_x1 > abs_x2:\n",
    "            abs_x1, abs_x2 = abs_x2, abs_x1\n",
    "\n",
    "        if abs_y1 > abs_y2:\n",
    "            abs_y1, abs_y2 = abs_y2, abs_y1\n",
    "\n",
    "        # Draw the bounding box\n",
    "        draw.rectangle(\n",
    "            ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline = color, width = 4\n",
    "        )\n",
    "\n",
    "        # Draw the text\n",
    "        if \"label\" in bounding_box:\n",
    "            draw.text((abs_x1 + 8, abs_y1 + 6), bounding_box[\"label\"], fill = color, font = font)\n",
    "\n",
    "    # Display the image\n",
    "    display(img)\n",
    "\n",
    "\n",
    "def plot_points(im, text, input_width, input_height):\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    colors = [\n",
    "        'red', 'green', 'blue', 'yellow', 'orange', 'pink', 'purple', 'brown', 'gray',\n",
    "        'beige', 'turquoise', 'cyan', 'magenta', 'lime', 'navy', 'maroon', 'teal',\n",
    "        'olive', 'coral', 'lavender', 'violet', 'gold', 'silver',\n",
    "    ] + additional_colors\n",
    "    xml_text = text.replace('```xml', '')\n",
    "    xml_text = xml_text.replace('```', '')\n",
    "    data = decode_xml_points(xml_text)\n",
    "    if data is None:\n",
    "        img.show()\n",
    "        return\n",
    "    points = data['points']\n",
    "    description = data['phrase']\n",
    "\n",
    "    font = ImageFont.truetype('./00_Dataset/NotoSansCJK-Regular.ttc', size = 14)\n",
    "\n",
    "    for i, point in enumerate(points):\n",
    "        color = colors[i % len(colors)]\n",
    "        abs_x1 = int(point[0])/input_width * width\n",
    "        abs_y1 = int(point[1])/input_height * height\n",
    "        radius = 2\n",
    "        draw.ellipse([(abs_x1 - radius, abs_y1 - radius), (abs_x1 + radius, abs_y1 + radius)], fill = color)\n",
    "        draw.text((abs_x1 + 8, abs_y1 + 6), description, fill = color, font = font)\n",
    "    \n",
    "    display(img)\n",
    "  \n",
    "\n",
    "# @title Parsing JSON output\n",
    "def parse_json(json_output):\n",
    "    # Parsing out the markdown fencing\n",
    "    lines = json_output.splitlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == \"```json\":\n",
    "            json_output = \"\\n\".join(lines[i+1:])  # Remove everything before \"```json\"\n",
    "            json_output = json_output.split(\"```\")[0]  # Remove everything after the closing \"```\"\n",
    "            break  # Exit the loop once \"```json\" is found\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    prompt,\n",
    "    image_path,\n",
    "    system_prompt = 'You are a helpful assistant',\n",
    "    max_new_tokens = 32000,\n",
    "    min_pixels = 512 * 28 * 28,\n",
    "    max_pixels = 2048 * 28 * 28\n",
    "):\n",
    "    messages = [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : [\n",
    "                {\n",
    "                    'type' : 'image',\n",
    "                    'image' : image_path,\n",
    "                    'min_pixels' : min_pixels,\n",
    "                    'max_pixels' : max_pixels,\n",
    "                },\n",
    "                {'type' : 'text', 'text' : prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Preparation for inference\n",
    "    text = processor.apply_chat_template(\n",
    "        messages, tokenize = False, add_generation_prompt = True\n",
    "    )\n",
    "    print('input:\\n', text)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = processor(\n",
    "        text = [text],\n",
    "        images = image_inputs,\n",
    "        videos = video_inputs,\n",
    "        padding = True,\n",
    "        return_tensors = 'pt',\n",
    "    )\n",
    "    inputs = inputs.to('cuda')\n",
    "\n",
    "    streamer = TextStreamer(processor.tokenizer, skip_special_tokens = True, skip_prompt = True)\n",
    "\n",
    "    # Inference: Generation of the output\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens = max_new_tokens, streamer = streamer)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens = True, clean_up_tokenization_spaces = False\n",
    "    )\n",
    "\n",
    "    print('output:\\n', output_text[0])\n",
    "\n",
    "    input_height = inputs['image_grid_thw'][0][1] * 14\n",
    "    input_width = inputs['image_grid_thw'][0][2] * 14\n",
    "\n",
    "    return output_text[0], input_height, input_width"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Run Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.01 Detect Certain Object in the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/cakes.png'\n",
    "# prompt in chinese\n",
    "prompt = '框出每一个小蛋糕的位置，以json格式输出所有的坐标'\n",
    "# prompt in english\n",
    "prompt = 'Outline the position of each small cake and output all the coordinates in JSON format.'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_bounding_boxes(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.02 Detect a Specific Object Using Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/cakes.png'\n",
    "# prompt in chinses\n",
    "prompt = '定位最右上角的棕色蛋糕，以JSON格式输出其bbox坐标'\n",
    "# prompt in english\n",
    "prompt = 'Locate the top right brown cake, output its bbox coordinates using JSON format.'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_bounding_boxes(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.03 Point to Certain Objects in XML Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/cakes.png'\n",
    "# prompt in chinese\n",
    "prompt = '以点的形式定位图中桌子远处的擀面杖，以XML格式输出其坐标'\n",
    "# prompt in english\n",
    "prompt = 'point to the rolling pin on the far side of the table, output its coordinates in XML format <points x y>object</points>'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_points(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.04 Reasoning Capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/Origamis.jpg'\n",
    "# prompt in chinese\n",
    "prompt = '框出图中纸狐狸的影子，以json格式输出其bbox坐标'\n",
    "# prompt in english\n",
    "prompt = 'Locate the shadow of the paper fox, report the bbox coordinates in JSON format.'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_bounding_boxes(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.05 Understand Relationships Across Different Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/cartoon_brave_person.jpeg'\n",
    "# prompt in chinese\n",
    "prompt = '框出图中见义勇为的人，以json格式输出其bbox坐标'\n",
    "# prompt in english\n",
    "prompt = 'Locate the person who act bravely, report the bbox coordinates in JSON format.'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_bounding_boxes(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.06 Find a Special Instance with Unique Characteristic (Color, Location, Utility, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/multiple_items.png'\n",
    "# prompt in chinese\n",
    "prompt = '如果太阳很刺眼，我应该用这张图中的什么物品，框出该物品在图中的bbox坐标，并以json格式输出'\n",
    "# prompt in english\n",
    "prompt = 'If the sun is very glaring, which item in this image should I use? Please locate it in the image with its bbox coordinates and its name and output in JSON format.'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_bounding_boxes(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.07 Use Qwen2.5-VL Grounding Capabilities to Help Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/multiple_items.png'\n",
    "# prompt in chinese\n",
    "prompt = '请以JSON格式输出图中所有物体bbox的坐标以及它们的名字，然后基于检测结果回答以下问题：图中物体的数目是多少？'\n",
    "# prompt in english\n",
    "prompt = 'Please first output bbox coordinates and names of every item in this image in JSON format, and then answer how many items are there in the image.'\n",
    "\n",
    "response, input_height, input_width = inference(prompt, image_path)\n",
    "\n",
    "image = Image.open(image_path)\n",
    "print(image.size)\n",
    "image.thumbnail([640,640], Image.Resampling.LANCZOS)\n",
    "plot_bounding_boxes(image, response, input_width, input_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_path = './00_Dataset/cakes.png'\n",
    "system_prompt = \"As an AI assistant, you specialize in accurate image object detection, delivering coordinates in plain text format 'x1,y1,x2,y2 object'.\"\n",
    "prompt = 'find all cakes'\n",
    "response, input_height, input_width = inference(prompt, image_path, system_prompt = system_prompt)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "omni_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
